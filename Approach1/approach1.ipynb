{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined and shuffled dataset saved to Data/combined_dataset_5_variables_dynamic_seed20777980.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sympy\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "PI = sympy.pi\n",
    "E = sympy.E\n",
    "PHI = (1 + sympy.sqrt(5))/2\n",
    "\n",
    "def random_constants():\n",
    "    constants = [PI, E, PHI, sympy.sqrt(2), -PI, -E, -PHI, -sympy.sqrt(2)]\n",
    "    return random.choice(constants)\n",
    "\n",
    "def random_coefficient():\n",
    "    if random.random() < 0.5:\n",
    "        return random.randint(-10, 10)\n",
    "    else:\n",
    "        return random.uniform(-5, 5)\n",
    "\n",
    "def generate_variables(n):\n",
    "    symbol_list = sympy.symbols(f'x0:{n}')\n",
    "    return symbol_list\n",
    "\n",
    "def generate_random_function_with_relevance(variables, num_relevant_vars, complexity_range=(3, 6)):\n",
    "    relevant_vars = random.sample(variables, num_relevant_vars)\n",
    "    num_ops = random.randint(*complexity_range)\n",
    "    function = random.choice(relevant_vars)\n",
    "    for _ in range(num_ops):\n",
    "        op = random.choice([sympy.Add, sympy.Mul, sympy.sin, sympy.cos, sympy.exp, sympy.Pow, sympy.tanh])\n",
    "        if op in [sympy.Add, sympy.Mul]:\n",
    "            function = op(function, random.choice(relevant_vars + [random_constants(), random_coefficient()]))\n",
    "        elif op == sympy.Pow:\n",
    "            function = op(function, random.choice([2, 3, 4]))\n",
    "        else:\n",
    "            function = op(function)\n",
    "    return function\n",
    "\n",
    "def generate_physics_function(variables):\n",
    "    functions = [\n",
    "        random_coefficient() * variables[0]**2 + random_coefficient() * variables[1],\n",
    "        sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]),\n",
    "        random_coefficient() * variables[0]**3 + random_coefficient() * variables[1]**2 + random_coefficient() * 3*variables[0]*variables[1],  # Polynomial function\n",
    "        random_coefficient() * (sympy.Mul(variables[0], 9.8)),\n",
    "        random_coefficient() * sympy.tanh(variables[0] + random_coefficient()) \n",
    "    ]\n",
    "    return random.choice(functions)\n",
    "\n",
    "def nguyen_benchmark_equations_dynamic(n=2, num_functions=100):\n",
    "    variables = generate_variables(n)\n",
    "    functions = []\n",
    "    for _ in range(num_functions):\n",
    "        num_relevant_vars = random.randint(1, n)\n",
    "        if random.random() > 0.5:\n",
    "            functions.append(generate_physics_function(variables))\n",
    "        else:\n",
    "            functions.append(generate_random_function_with_relevance(variables, num_relevant_vars))\n",
    "    return functions\n",
    "\n",
    "def evaluate_nguyen_benchmark_equations_with_relevant_variables(functions, num_samples=100, range_vals=(-1, 1)):\n",
    "    dataset = []\n",
    "    for func in functions:\n",
    "        data = {\"x\": {}, \"y\": []}\n",
    "        skeleton = create_skeleton(func)\n",
    "        num_vars = max([int(str(var)[1:]) for var in func.free_symbols]) + 1\n",
    "        all_variables = generate_variables(num_vars)\n",
    "        \n",
    "        for var in all_variables:\n",
    "            data[\"x\"][str(var)] = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            inputs = {str(var): np.random.uniform(*range_vals) for var in all_variables}\n",
    "            relevant_inputs = {str(var): inputs[str(var)] for var in func.free_symbols}\n",
    "            try:\n",
    "                result = func.evalf(subs=relevant_inputs)\n",
    "                if result.is_real:\n",
    "                    output = float(result)\n",
    "                else:\n",
    "                    logger.warning(f\"Complex result for {str(func)}: {result}. Skipping this data point.\")\n",
    "                    continue \n",
    "                for var in all_variables:\n",
    "                    data[\"x\"][str(var)].append(inputs[str(var)])\n",
    "                data[\"y\"].append(output)\n",
    "            except (ValueError, ZeroDivisionError, OverflowError) as e:\n",
    "                logger.warning(f\"Invalid expression for {str(func)}: {e}\")\n",
    "                continue\n",
    "\n",
    "        dataset.append({\"function\": str(func), \"skeleton\": skeleton, \"data\": data})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def save_to_json_line_by_line(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for data_point in data:\n",
    "            json.dump(data_point, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def create_skeleton(input_function):\n",
    "    input_function_str = str(input_function)\n",
    "    scientific_constants = [sympy.pi, sympy.E, (1 + sympy.sqrt(5))/2]\n",
    "    for constant in scientific_constants:\n",
    "        input_function_str = input_function_str.replace(str(constant), 'C')\n",
    "    skeleton = re.sub(r\"sqrt\\(([+-]?\\d*\\.?\\d+)\\)\", \"C\", input_function_str)\n",
    "    skeleton = re.sub(r\"exp\\(([+-]?\\d*\\.?\\d+)\\)\", \"C\", skeleton)\n",
    "    skeleton = re.sub(\n",
    "        r\"([+-]?\\d*\\.?\\d+)(?=[a-zA-Z(])\",\n",
    "        \"C\",\n",
    "        skeleton\n",
    "    )\n",
    "    skeleton = re.sub(\n",
    "        r\"(?<![\\w^*])([+-]?\\d*\\.?\\d+)(?![*]{2})\",\n",
    "        \"C\",\n",
    "        skeleton\n",
    "    )\n",
    "    skeleton = re.sub(r\"-\\s*C\", \"+ C\", skeleton)\n",
    "    skeleton = re.sub(r\"C\\s*/\\s*C\", \"C\", skeleton)\n",
    "    skeleton = re.sub(r\"C\\s*\\+\\s*C\", \"C\", skeleton)\n",
    "    skeleton = re.sub(r\"\\(C\\)\", \"C\", skeleton)\n",
    "    skeleton = re.sub(r\"-\\s*C\", \"C\", skeleton)\n",
    "    skeleton = re.sub(r\"^\\-\", \"C*\", skeleton)\n",
    "    return skeleton\n",
    "\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_variables = 5 \n",
    "num_functions = 100 \n",
    "\n",
    "nguyen_functions = nguyen_benchmark_equations_dynamic(n_variables, num_functions)\n",
    "\n",
    "\n",
    "nguyen_benchmark_equations_evaluated = evaluate_nguyen_benchmark_equations_with_relevant_variables(nguyen_functions, num_samples=100, range_vals=(-1, 1))\n",
    "\n",
    "file_path_combined = f\"Data/combined_dataset_{n_variables}_variables_dynamic_seed{seed}.json\"\n",
    "save_to_json_line_by_line(nguyen_benchmark_equations_evaluated, file_path_combined)\n",
    "\n",
    "print(f\"Combined and shuffled dataset saved to {file_path_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.0\n",
      "Epoch 2/50, Train Loss: 0.0\n",
      "Epoch 3/50, Train Loss: 0.0\n",
      "Epoch 4/50, Train Loss: 0.0\n",
      "Early stopping occurred at epoch 4\n",
      "Preprocessing complete with embeddings. Data saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "NOISE_LEVEL = 0.1\n",
    "EMBEDDING_DIM = 100\n",
    "EPOCHS = 50\n",
    "PATIENCE = 3\n",
    "MIN_DELTA = 0.0001\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)\n",
    "        \n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        assert x.size(1) == 4 * self.n_embd\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "def tokenize_skeleton(skeleton_str):\n",
    "    skeleton_str = skeleton_str.replace(\"**\", \"^\")\n",
    "    pattern = r'[a-zA-Z_][a-zA-Z0-9_]*|[+\\-*/^(),.]|C|sin|cos|log|exp|sqrt'\n",
    "    tokens = re.findall(pattern, skeleton_str)\n",
    "    return tokens\n",
    "\n",
    "def train_word2vec_embeddings(dataset, embedding_dim=EMBEDDING_DIM, epochs=EPOCHS, patience_num_epochs=PATIENCE):\n",
    "    sentences = []\n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokens = tokenize_skeleton(skeleton_str)\n",
    "        sentences.append(tokens)\n",
    "    \n",
    "    model = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4, epochs=1)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "\n",
    "    performance_metrics_DICT = {\n",
    "        \"epoch_list\": [],\n",
    "        \"train_loss_list\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs-1):\n",
    "        model.train(sentences, total_examples=model.corpus_count, epochs=1)\n",
    "        current_loss = model.get_latest_training_loss()\n",
    "        performance_metrics_DICT['epoch_list'].append(epoch+1)\n",
    "        performance_metrics_DICT['train_loss_list'].append(current_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {current_loss}\")\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            model.save(\"Data/embeddings_model.model\")\n",
    "            num_epochs_without_improvement = 0\n",
    "            save_JSON(performance_metrics_DICT,'Data/embeddings_performance_metrics_DICT.json')\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f'Early stopping occurred at epoch {epoch + 1}')\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        model.save(\"Data/embeddings_model.model\")\n",
    "        save_JSON(performance_metrics_DICT,'Data/embeddings_performance_metrics_DICT.json')\n",
    "    return model, performance_metrics_DICT\n",
    "\n",
    "def build_vocab_and_embeddings(dataset, model=None):\n",
    "    token_set = set()\n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokens = tokenize_skeleton(skeleton_str)\n",
    "        token_set.update(tokens)\n",
    "    vocab_embeddings = {}\n",
    "    if model:\n",
    "        for token in token_set:\n",
    "            if token in model.wv:\n",
    "                embedding = model.wv[token]\n",
    "                embedding = normalize([embedding])[0]\n",
    "                vocab_embeddings[token] = embedding\n",
    "            else:\n",
    "                vocab_embeddings[token] = np.random.uniform(-0.1, 0.1, size=EMBEDDING_DIM)\n",
    "    else:\n",
    "        for token in token_set:\n",
    "            vocab_embeddings[token] = np.random.uniform(-0.1, 0.1, size=EMBEDDING_DIM)\n",
    "    vocab_embeddings[PAD_TOKEN] = np.zeros(EMBEDDING_DIM)\n",
    "    return vocab_embeddings\n",
    "\n",
    "def standardize_data(data):\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_std = np.std(data, axis=0)    \n",
    "    data_standardized = (data - data_mean)/data_std\n",
    "    return data_standardized\n",
    "\n",
    "def tokenize_dataset_with_embeddings(dataset, vocab_embeddings):\n",
    "    tokenized_data = []\n",
    "        \n",
    "    max_num_features  = max(len(entry['data']['x']) for entry in dataset)\n",
    "    \n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokenized_skeleton = [vocab_embeddings[token] for token in tokenize_skeleton(skeleton_str)]\n",
    "        \n",
    "        data = entry[\"data\"]\n",
    "        x_DICT = data['x'] \n",
    "                    \n",
    "        num_data_points = len(x_DICT[list(x_DICT.keys())[0]])\n",
    "        num_features = len(list(x_DICT.keys()))\n",
    "                \n",
    "        x_with_values_MAT = np.array(list(x_DICT.values())).T\n",
    "        x_with_values_standardized_MAT = standardize_data(x_with_values_MAT)\n",
    "        nan_MAT = np.full((num_data_points, max_num_features-num_features), np.nan)\n",
    "        x_standardized_MAT = np.concatenate((x_with_values_standardized_MAT, nan_MAT), axis=1)        \n",
    "        \n",
    "        y = np.array(data['y'])\n",
    "        y_standardized = standardize_data(y)\n",
    "        \n",
    "        mask = np.array([1]*num_features + [0]*(max_num_features-num_features))        \n",
    "        \n",
    "        data_DICT = {'x': x_standardized_MAT, 'y': y_standardized, 'mask': mask}\n",
    "        \n",
    "        tokenized_data.append({\n",
    "            \"tokens\": tokenized_skeleton,\n",
    "            \"data\": data_DICT,\n",
    "            \"skeleton\": skeleton_str\n",
    "        })\n",
    "    \n",
    "    return tokenized_data\n",
    "\n",
    "def pad_sequences(tokenized_data, max_length, pad_embedding, pad_token=PAD_TOKEN):\n",
    "    \"\"\"Pad tokenized sequences to a fixed length.\"\"\" \n",
    "    for dp in tokenized_data:\n",
    "        token_length = len(dp[\"tokens\"])\n",
    "        if token_length < max_length:\n",
    "            dp[\"tokens\"] = dp[\"tokens\"] + [pad_embedding]*(max_length - token_length)\n",
    "        elif token_length > max_length:\n",
    "            dp[\"tokens\"] = dp[\"tokens\"][:max_length]\n",
    "    return tokenized_data\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def add_TNet_embeddings(preprocessed_data):\n",
    "    tokenized_formulas = torch.tensor([datapoint['tokens'] for datapoint in preprocessed_data]).float()\n",
    "    datasets = torch.tensor([np.concatenate((datapoint['data']['x'], datapoint['data']['y'].reshape(len(datapoint['data']['y']),1)), axis=1) for datapoint in preprocessed_data])\n",
    "    datasets = torch.nan_to_num(datasets,nan=0.0).float()\n",
    "\n",
    "    batch_size, seq_len, embedding_dim = tokenized_formulas.shape\n",
    "    batch_size, num_points, num_features = datasets.shape\n",
    "\n",
    "    config_formula = tNetConfig(num_vars=seq_len, embedding_size=128) \n",
    "    config_data = tNetConfig(num_vars=num_points, embedding_size=128)\n",
    "\n",
    "    TNet_model_formula = tNet(config_formula) \n",
    "    TNet_model_data = tNet(config_data)\n",
    "\n",
    "    formula_embeddings = TNet_model_formula(tokenized_formulas)  # Shape: [num_formulas, embedding_size]\n",
    "    dataset_embeddings = TNet_model_data(datasets)  # Shape: [batch_size, embedding_size]\n",
    "\n",
    "    formula_embeddings = formula_embeddings.detach().cpu().numpy()\n",
    "    dataset_embeddings = dataset_embeddings.detach().cpu().numpy()\n",
    "\n",
    "    # Add embeddings to each datapoint in preprocessed_data\n",
    "    for i, datapoint in enumerate(preprocessed_data):\n",
    "        datapoint['formula_embedding'] = formula_embeddings[i]\n",
    "        datapoint['dataset_embedding'] = dataset_embeddings[i]\n",
    "    return preprocessed_data\n",
    "\n",
    "def preprocess_and_tokenize_dataset(file_path, model=None, noise_type=\"gaussian\", noise_level=NOISE_LEVEL, max_length='max_length'):\n",
    "    # Step 1: Load dataset\n",
    "    dataset = load_dataset(file_path)\n",
    "\n",
    "    # Step 2: Train Word2Vec model if not provided\n",
    "    if model is None:\n",
    "        model, performance_metrics_DICT = train_word2vec_embeddings(dataset)\n",
    "\n",
    "    # Step 3: Build vocabulary with embeddings\n",
    "    vocab_embeddings = build_vocab_and_embeddings(dataset, model)\n",
    "\n",
    "    # Step 4: Tokenize dataset and convert tokens to embeddings\n",
    "    tokenized_data = tokenize_dataset_with_embeddings(dataset, vocab_embeddings)\n",
    "\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in tokenized_data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    \n",
    "    # Step 7: Pad sequences to a fixed length\n",
    "    padded_data = pad_sequences(tokenized_data,MAX_LENGTH,vocab_embeddings['<PAD>'])\n",
    "    \n",
    "    preprocessed_data = add_TNet_embeddings(padded_data)\n",
    "    \n",
    "    return padded_data, vocab_embeddings, model, performance_metrics_DICT\n",
    "\n",
    "# Save preprocessed data\n",
    "def save_preprocessed_data(data, output_path):\n",
    "    \"\"\"Save the preprocessed data to a file with JSON serialization.\"\"\"\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert ndarray to list\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [convert_to_serializable(item) for item in obj]\n",
    "        return obj  # Return the object as-is if it's already serializable\n",
    "\n",
    "    with open(output_path, 'w') as file:\n",
    "        for dp in data:\n",
    "            json.dump(convert_to_serializable(dp), file)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file with support for NumPy arrays.\"\"\"\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert ndarray to list\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "        return obj  # Return the object as-is if it's already serializable\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(convert_to_serializable(data), f)\n",
    "        \n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main script execution\n",
    "file_path = \"Data/combined_dataset_5_variables_dynamic_seed940.json\"\n",
    "\n",
    "# Process the data and train Word2Vec embeddings\n",
    "preprocessed_data, vocab_embeddings, model, performance_metrics_DICT = preprocess_and_tokenize_dataset(file_path)\n",
    "\n",
    "# Save the preprocessed data, vocab embeddings, and trained Word2Vec model\n",
    "save_preprocessed_data(preprocessed_data, \"Data/preprocessed_data_with_embeddings.json\")\n",
    "save_JSON(vocab_embeddings, \"Data/vocab_embeddings.json\")\n",
    "\n",
    "print(\"Preprocessing complete with embeddings. Data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Performance Metrics:\n",
      "{'epoch_list': [1], 'train_loss_list': [0.0]}\n"
     ]
    }
   ],
   "source": [
    "performance_metrics_DICT = load_JSON('Data/embeddings_performance_metrics_DICT.json')\n",
    "model = Word2Vec.load(\"Data/embeddings_model.model\")\n",
    "\n",
    "print(\"Embeddings Performance Metrics:\")\n",
    "print(performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diffusion Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.23779887557029725, Val Loss: 0.4486483931541443\n",
      "Epoch 2/100, Train Loss: 0.10243501961231231, Val Loss: 0.4412689507007599\n",
      "Epoch 3/100, Train Loss: 0.059051104635000226, Val Loss: 0.43448907136917114\n",
      "Epoch 4/100, Train Loss: 0.03806477934122086, Val Loss: 0.42765307426452637\n",
      "Epoch 5/100, Train Loss: 0.028167488798499108, Val Loss: 0.42596903443336487\n",
      "Epoch 6/100, Train Loss: 0.023289132118225097, Val Loss: 0.4268840551376343\n",
      "Epoch 7/100, Train Loss: 0.02140187583863735, Val Loss: 0.42439475655555725\n",
      "Epoch 8/100, Train Loss: 0.019652978330850602, Val Loss: 0.4292699992656708\n",
      "Epoch 9/100, Train Loss: 0.01858958601951599, Val Loss: 0.42538952827453613\n",
      "Epoch 10/100, Train Loss: 0.01812881454825401, Val Loss: 0.42740288376808167\n",
      "Epoch 11/100, Train Loss: 0.01749928668141365, Val Loss: 0.4254731237888336\n",
      "Epoch 12/100, Train Loss: 0.017029761523008346, Val Loss: 0.42796412110328674\n",
      "Epoch 13/100, Train Loss: 0.01678049601614475, Val Loss: 0.42996978759765625\n",
      "Epoch 14/100, Train Loss: 0.016441794484853743, Val Loss: 0.424726277589798\n",
      "Epoch 15/100, Train Loss: 0.01596267372369766, Val Loss: 0.4221039414405823\n",
      "Epoch 16/100, Train Loss: 0.015852971002459526, Val Loss: 0.42684200406074524\n",
      "Epoch 17/100, Train Loss: 0.015405166149139404, Val Loss: 0.4217410087585449\n",
      "Epoch 18/100, Train Loss: 0.015238349325954914, Val Loss: 0.42433297634124756\n",
      "Epoch 19/100, Train Loss: 0.014891835860908031, Val Loss: 0.4320971965789795\n",
      "Epoch 20/100, Train Loss: 0.014647636003792286, Val Loss: 0.42630451917648315\n",
      "Epoch 21/100, Train Loss: 0.014527326449751854, Val Loss: 0.42593804001808167\n",
      "Epoch 22/100, Train Loss: 0.014203350618481636, Val Loss: 0.4247186481952667\n",
      "Epoch 23/100, Train Loss: 0.013994108326733113, Val Loss: 0.425071656703949\n",
      "Epoch 24/100, Train Loss: 0.013706809654831887, Val Loss: 0.4283972680568695\n",
      "Epoch 25/100, Train Loss: 0.013522388972342014, Val Loss: 0.422078400850296\n",
      "Epoch 26/100, Train Loss: 0.013445437513291835, Val Loss: 0.4253804385662079\n",
      "Epoch 27/100, Train Loss: 0.013082524947822093, Val Loss: 0.4281878173351288\n",
      "Training stopped early at epoch 27. Best validation loss: 0.4217410087585449\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)\n",
    "        \n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        x, _ = torch.max(x, dim=2) \n",
    "        assert x.size(1) == 4*self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "        self.data = data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def get_input_embeddings(self, tokens):\n",
    "        embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "        padded_embeddings = nn.functional.pad(embeddings, (0, self.max_seq_len - embeddings.size(0)))\n",
    "        padded_embeddings = padded_embeddings.transpose(0,1)\n",
    "        return padded_embeddings\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        tokens = data_point['tokens']\n",
    "        current_data = data_point['data']\n",
    "        x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "        y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "        mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "        token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        \n",
    "        noisy_x = self.add_noise(x, t, self.noise_schedule)\n",
    "        noisy_y = self.add_noise(y, t, self.noise_schedule)\n",
    "        \n",
    "        skeleton = data_point['skeleton']\n",
    "        \n",
    "        return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, t, mask, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None, tnet_config=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.tnet = tNet(tnet_config) if tnet_config is not None else None\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "            if pretrained_embeddings.size(1) != embedding_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "                )\n",
    "            self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "        if self.embedding_dim != self.hidden_dim:\n",
    "            embeddings = self.projection(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        logits = self.fc_out(embeddings)\n",
    "        logits = logits.transpose(1, 2)\n",
    "        return logits\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "    \n",
    "    def reverse_diffusion(self, noisy_input, schedule):\n",
    "        x_t = noisy_input\n",
    "        device = x_t.device\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            predicted_noise = self.tnet(x_t) if self.tnet is not None else self.forward(x_t)\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in train_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            mask = mask.to(device) if mask is not None else None\n",
    "            optimizer.zero_grad()\n",
    "            predicted_embeddings = model(noisy_token_embeddings)\n",
    "            loss = denoising_loss(predicted_embeddings, token_embeddings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in val_loader:\n",
    "                token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "                mask = mask.to(device) if mask is not None else None\n",
    "                denoised_token_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "                loss = denoising_loss(denoised_token_embeddings, token_embeddings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        save_model(model, \"../Data/best_diffusion_model_method1.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\") \n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "train_size = int(0.7*len(dataset))\n",
    "val_size = int(0.15*len(dataset))\n",
    "test_size = len(dataset)-train_size-val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "num_heads = 4\n",
    "embedding_dim = 100\n",
    "hidden_dim = embedding_dim\n",
    "\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_3308\\1325211605.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filepath))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "    plt.figure();\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "    plt.title(f'{model_name} Training and Validation Loss');\n",
    "    plt.xlabel('Epochs');\n",
    "    plt.ylabel('Loss');\n",
    "    plt.legend();\n",
    "    plt.grid();\n",
    "    plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Diffusion Model'\n",
    "\n",
    "plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_3308\\1325211605.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filepath))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9628666043281555\n",
      "Predicted Formula: ['Cx3x4 + x3tanhCx0x4cos(x2*', ' + ^tanhx3x4x4x3CC)tanhexp', 'x2tanhcosx2Csinexpx4x3tanh + tanhx3x2cosx4', 'x4x2sin +  + ^x3x2sinx4expx0 + C)x1', 'C)x1x1x3)C(x2(cosx4', '^*cosx3tanhx3expx1x4x4cosx3x4', 'x1expx3 + x2expexpx4sincosx1', 'sinx4x3^^tanhx2expx1)', 'cosx1*(expx2x0x3x2 + expx0', 'x3tanhx1exp) + x4Cx4Cx1', ')x0*x3^ + *x3Cx3x1x3x3', '*x2expsinCx4x4 + exptanhx4x3', 'expcossinx1x3x2C**coscosC', '^cos^expx3x4x0sinx1x4x0C', 'x2x0x0expsinsintanhC']\n",
      "Actual Formula: ['cos(tanh(exp(x2)))', 'C*tanh(x0 + C)', 'C*tanh(x0 + C)', 'C*x0**3 + C*x0*x1 + C*x1**2', 'C*tanh(x0 + C)', 'sin(x0) + C*cos(x1)', 'cos(C*exp(x4))**3', 'x2*tanh(sin(tanh(x3)) + C)', 'C*sin(x2**24)', 'sin(cos(sin(tanh(x3**2)))) + C', 'C*x0**2 + C*x1', 'C*x0**3 + C*x0*x1 + C*x1**2', 'tanh(sin(cos(sin(C*x2*x4))))', 'C*tanh(x0 + C)', 'x0 + cos(cos(exp(x1)))']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "    batch_size, embedding_dim, seq_length = embeddings.shape\n",
    "    vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])\n",
    "    embeddings_flattened = embeddings.view(batch_size*seq_length, embedding_dim)\n",
    "    distances = torch.cdist(embeddings_flattened, vocab_embeddings)\n",
    "    distances = distances.view(batch_size, seq_length, -1)\n",
    "    closest_token_indices = torch.argmin(distances, dim=-1)\n",
    "    decoded_tokens = []\n",
    "    for batch_idx in range(batch_size):\n",
    "        tokens = [list(vocab.keys())[idx.item()] for idx in closest_token_indices[batch_idx]]\n",
    "        decoded_tokens.append(tokens)\n",
    "    return decoded_tokens\n",
    "\n",
    "def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    decoded_formulas = []\n",
    "    actual_formulas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton_list in test_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            t = random.randint(0, model.num_timesteps - 1)\n",
    "            pred_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "            loss = denoising_loss(pred_embeddings, noisy_token_embeddings)\n",
    "            total_test_loss += loss.item()\n",
    "            decoded_tokens_list = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "            predicted_formula = [\"\".join(decoded_tokens).replace('<PAD>', '').replace('+', ' + ') for decoded_tokens in decoded_tokens_list]\n",
    "            decoded_formulas.append(predicted_formula)\n",
    "            actual_formula = list(skeleton_list)\n",
    "            actual_formulas.append(actual_formula)\n",
    "    avg_test_loss = total_test_loss/len(test_loader)\n",
    "    return avg_test_loss, decoded_formulas, actual_formulas\n",
    "\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "train_size = int(0.7*len(dataset))\n",
    "val_size = int(0.15*len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size \n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "num_heads = 4\n",
    "embedding_dim = 100\n",
    "hidden_dim = embedding_dim\n",
    "\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model, device = load_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "    print(f\"Predicted Formula: {predicted}\")\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Attempt With Cross Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7206235289573669, Val Loss: 0.6199209690093994\n",
      "Epoch 2/100, Train Loss: 0.46560250520706176, Val Loss: 0.6199209690093994\n",
      "Epoch 3/100, Train Loss: 0.3378569185733795, Val Loss: 0.6199209690093994\n",
      "Epoch 4/100, Train Loss: 0.2589802235364914, Val Loss: 0.6199209690093994\n",
      "Epoch 5/100, Train Loss: 0.214978489279747, Val Loss: 0.6199209690093994\n",
      "Epoch 6/100, Train Loss: 0.1942541182041168, Val Loss: 0.6199209690093994\n",
      "Epoch 7/100, Train Loss: 0.17953898012638092, Val Loss: 0.6199209690093994\n",
      "Epoch 8/100, Train Loss: 0.17081521451473236, Val Loss: 0.6199209690093994\n",
      "Epoch 9/100, Train Loss: 0.16131505072116853, Val Loss: 0.6199209690093994\n",
      "Epoch 10/100, Train Loss: 0.1597515672445297, Val Loss: 0.6199209690093994\n",
      "Epoch 11/100, Train Loss: 0.14926388263702392, Val Loss: 0.6199209690093994\n",
      "Epoch 12/100, Train Loss: 0.1479350209236145, Val Loss: 0.6199209690093994\n",
      "Epoch 13/100, Train Loss: 0.14628997445106506, Val Loss: 0.6199209690093994\n",
      "Epoch 14/100, Train Loss: 0.1413947492837906, Val Loss: 0.6199209690093994\n",
      "Epoch 15/100, Train Loss: 0.14508646130561828, Val Loss: 0.6199209690093994\n",
      "Epoch 16/100, Train Loss: 0.14382776618003845, Val Loss: 0.6199209690093994\n",
      "Epoch 17/100, Train Loss: 0.14063076972961425, Val Loss: 0.6199209690093994\n",
      "Epoch 18/100, Train Loss: 0.14094341099262236, Val Loss: 0.6199209690093994\n",
      "Epoch 19/100, Train Loss: 0.1401250571012497, Val Loss: 0.6199209690093994\n",
      "Epoch 20/100, Train Loss: 0.13966304957866668, Val Loss: 0.6199209690093994\n",
      "Epoch 21/100, Train Loss: 0.1380559027194977, Val Loss: 0.6199209690093994\n",
      "Epoch 22/100, Train Loss: 0.13773658275604247, Val Loss: 0.6199209690093994\n",
      "Epoch 23/100, Train Loss: 0.13765364289283752, Val Loss: 0.6199209690093994\n",
      "Epoch 24/100, Train Loss: 0.13779976069927216, Val Loss: 0.6199209690093994\n",
      "Epoch 25/100, Train Loss: 0.13831033706665039, Val Loss: 0.6199209690093994\n",
      "Epoch 26/100, Train Loss: 0.13659653663635254, Val Loss: 0.6199209690093994\n",
      "Epoch 27/100, Train Loss: 0.1340498834848404, Val Loss: 0.6199209690093994\n",
      "Epoch 28/100, Train Loss: 0.13933752179145814, Val Loss: 0.6199209690093994\n",
      "Epoch 29/100, Train Loss: 0.13627262711524962, Val Loss: 0.6199209690093994\n",
      "Epoch 30/100, Train Loss: 0.14032966792583465, Val Loss: 0.6199209690093994\n",
      "Epoch 31/100, Train Loss: 0.13724209368228912, Val Loss: 0.6199209690093994\n",
      "Epoch 32/100, Train Loss: 0.13973080813884736, Val Loss: 0.6199209690093994\n",
      "Epoch 33/100, Train Loss: 0.1352227210998535, Val Loss: 0.6199209690093994\n",
      "Epoch 34/100, Train Loss: 0.13777195513248444, Val Loss: 0.6199209690093994\n",
      "Epoch 35/100, Train Loss: 0.13965288698673248, Val Loss: 0.6199209690093994\n",
      "Epoch 36/100, Train Loss: 0.13929089903831482, Val Loss: 0.6199209690093994\n",
      "Epoch 37/100, Train Loss: 0.13589569330215454, Val Loss: 0.6199209690093994\n",
      "Epoch 38/100, Train Loss: 0.13641760051250457, Val Loss: 0.6199209690093994\n",
      "Epoch 39/100, Train Loss: 0.13944524228572847, Val Loss: 0.6199209690093994\n",
      "Epoch 40/100, Train Loss: 0.13653745949268342, Val Loss: 0.6199209690093994\n",
      "Epoch 41/100, Train Loss: 0.14010678231716156, Val Loss: 0.6199209690093994\n",
      "Epoch 42/100, Train Loss: 0.13581314384937287, Val Loss: 0.6199209690093994\n",
      "Epoch 43/100, Train Loss: 0.13770573139190673, Val Loss: 0.6199209690093994\n",
      "Epoch 44/100, Train Loss: 0.1381816416978836, Val Loss: 0.6199209690093994\n",
      "Epoch 45/100, Train Loss: 0.1372412383556366, Val Loss: 0.6199209690093994\n",
      "Epoch 46/100, Train Loss: 0.13964733779430388, Val Loss: 0.6199209690093994\n",
      "Epoch 47/100, Train Loss: 0.13706936836242675, Val Loss: 0.6199209690093994\n",
      "Epoch 48/100, Train Loss: 0.1359063059091568, Val Loss: 0.6199209690093994\n",
      "Epoch 49/100, Train Loss: 0.13578867316246032, Val Loss: 0.6199209690093994\n",
      "Epoch 50/100, Train Loss: 0.13504832088947297, Val Loss: 0.6199209690093994\n",
      "Epoch 51/100, Train Loss: 0.13913078010082244, Val Loss: 0.6199209690093994\n",
      "Epoch 52/100, Train Loss: 0.13800675868988038, Val Loss: 0.6199209690093994\n",
      "Epoch 53/100, Train Loss: 0.1394233912229538, Val Loss: 0.6199209690093994\n",
      "Epoch 54/100, Train Loss: 0.14018962383270264, Val Loss: 0.6199209690093994\n",
      "Epoch 55/100, Train Loss: 0.13520313203334808, Val Loss: 0.6199209690093994\n",
      "Epoch 56/100, Train Loss: 0.13394689559936523, Val Loss: 0.6199209690093994\n",
      "Epoch 57/100, Train Loss: 0.13681080639362336, Val Loss: 0.6199209690093994\n",
      "Epoch 58/100, Train Loss: 0.13942002058029174, Val Loss: 0.6199209690093994\n",
      "Epoch 59/100, Train Loss: 0.13812209963798522, Val Loss: 0.6199209690093994\n",
      "Epoch 60/100, Train Loss: 0.1383316546678543, Val Loss: 0.6199209690093994\n",
      "Epoch 61/100, Train Loss: 0.13680026233196257, Val Loss: 0.6199209690093994\n",
      "Epoch 62/100, Train Loss: 0.13962289988994597, Val Loss: 0.6199209690093994\n",
      "Epoch 63/100, Train Loss: 0.13326553702354432, Val Loss: 0.6199209690093994\n",
      "Epoch 64/100, Train Loss: 0.13877361118793488, Val Loss: 0.6199209690093994\n",
      "Epoch 65/100, Train Loss: 0.13959548771381378, Val Loss: 0.6199209690093994\n",
      "Epoch 66/100, Train Loss: 0.1424848437309265, Val Loss: 0.6199209690093994\n",
      "Epoch 67/100, Train Loss: 0.13769370019435884, Val Loss: 0.6199209690093994\n",
      "Epoch 68/100, Train Loss: 0.14380577206611633, Val Loss: 0.6199209690093994\n",
      "Epoch 69/100, Train Loss: 0.1353621929883957, Val Loss: 0.6199209690093994\n",
      "Epoch 70/100, Train Loss: 0.13725090324878692, Val Loss: 0.6199209690093994\n",
      "Epoch 71/100, Train Loss: 0.13729995787143706, Val Loss: 0.6199209690093994\n",
      "Epoch 72/100, Train Loss: 0.13669239580631257, Val Loss: 0.6199209690093994\n",
      "Epoch 73/100, Train Loss: 0.1365759015083313, Val Loss: 0.6199209690093994\n",
      "Epoch 74/100, Train Loss: 0.13437871336936952, Val Loss: 0.6199209094047546\n",
      "Epoch 75/100, Train Loss: 0.13812992870807647, Val Loss: 0.6199209690093994\n",
      "Epoch 76/100, Train Loss: 0.1377488672733307, Val Loss: 0.6199209690093994\n",
      "Epoch 77/100, Train Loss: 0.1378587454557419, Val Loss: 0.6199209690093994\n",
      "Epoch 78/100, Train Loss: 0.13744878768920898, Val Loss: 0.6199209690093994\n",
      "Epoch 79/100, Train Loss: 0.13984255492687225, Val Loss: 0.6199209690093994\n",
      "Epoch 80/100, Train Loss: 0.13995029926300048, Val Loss: 0.6199209690093994\n",
      "Epoch 81/100, Train Loss: 0.1376222401857376, Val Loss: 0.6199209690093994\n",
      "Epoch 82/100, Train Loss: 0.13722145259380342, Val Loss: 0.6199209690093994\n",
      "Epoch 83/100, Train Loss: 0.138803169131279, Val Loss: 0.6199209690093994\n",
      "Epoch 84/100, Train Loss: 0.1342374086380005, Val Loss: 0.6199209690093994\n",
      "Epoch 85/100, Train Loss: 0.13654062449932097, Val Loss: 0.6199209094047546\n",
      "Epoch 86/100, Train Loss: 0.1401545822620392, Val Loss: 0.6199209690093994\n",
      "Epoch 87/100, Train Loss: 0.1401611626148224, Val Loss: 0.6199209690093994\n",
      "Epoch 88/100, Train Loss: 0.13846067488193511, Val Loss: 0.6199209690093994\n",
      "Epoch 89/100, Train Loss: 0.1396716445684433, Val Loss: 0.6199209690093994\n",
      "Epoch 90/100, Train Loss: 0.13871659934520722, Val Loss: 0.6199209690093994\n",
      "Epoch 91/100, Train Loss: 0.13867261111736298, Val Loss: 0.6199209690093994\n",
      "Epoch 92/100, Train Loss: 0.13873914182186126, Val Loss: 0.6199209690093994\n",
      "Epoch 93/100, Train Loss: 0.1380009800195694, Val Loss: 0.6199209690093994\n",
      "Epoch 94/100, Train Loss: 0.13616972267627717, Val Loss: 0.6199209690093994\n",
      "Epoch 95/100, Train Loss: 0.13817777037620543, Val Loss: 0.6199209690093994\n",
      "Epoch 96/100, Train Loss: 0.1350281298160553, Val Loss: 0.6199209690093994\n",
      "Epoch 97/100, Train Loss: 0.1390557110309601, Val Loss: 0.6199209690093994\n",
      "Epoch 98/100, Train Loss: 0.13901992440223693, Val Loss: 0.6199209690093994\n",
      "Epoch 99/100, Train Loss: 0.13614541590213775, Val Loss: 0.6199209690093994\n",
      "Epoch 100/100, Train Loss: 0.1386029303073883, Val Loss: 0.6199209690093994\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def load_dataset_torch(filepath):\n",
    "    loaded_data = torch.load(filepath)\n",
    "    formula_embeddings = loaded_data['formula_embeddings']\n",
    "    dataset_embeddings = loaded_data['dataset_embeddings']\n",
    "    return formula_embeddings,dataset_embeddings\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)\n",
    "        \n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        assert x.size(1) == 4*self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi/2, timesteps, device=device))**2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data, vocab, max_seq_len, noise_schedule):\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "    \n",
    "    def add_noise(self, embeddings, t):\n",
    "        alpha_t = self.noise_schedule.get_alpha(t)\n",
    "        beta_t = self.noise_schedule.get_beta(t)\n",
    "        noise = torch.randn_like(embeddings)*torch.sqrt(beta_t)\n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*embeddings + noise\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.preprocessed_data[idx]\n",
    "        formula_emb = torch.tensor(data_point['formula_embedding'], dtype=torch.float32)\n",
    "        dataset_emb =  torch.tensor(data_point['dataset_embedding'], dtype=torch.float32)\n",
    "        skeleton = data_point['skeleton']\n",
    "\n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_formula_emb = self.add_noise(formula_emb, t)\n",
    "        return formula_emb, noisy_formula_emb, dataset_emb, t, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessed_data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        batch_size, embedding_dim = embeddings.shape\n",
    "        embeddings = self.projection(embeddings)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.unsqueeze(0) \n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.squeeze(0)\n",
    "        logits = self.fc_out(embeddings)\n",
    "        return logits\n",
    "\n",
    "    def reverse_diffusion(self, noisy_formula_embeddings, dataset_embeddings, schedule):\n",
    "        device = noisy_formula_embeddings.device\n",
    "        batch_size, embedding_dim = noisy_formula_embeddings.size()\n",
    "        x_t = noisy_formula_embeddings\n",
    "        \n",
    "        tnet = tNet(tNetConfig(num_vars=batch_size,embedding_size=embedding_dim))\n",
    "        \n",
    "        dataset_embeddings = dataset_embeddings.unsqueeze(1)\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            query = x_t.unsqueeze(1)  # [B, 1, D]\n",
    "            conditioned_embedding, _ = self.cross_attention(\n",
    "                query=query,\n",
    "                key=dataset_embeddings,\n",
    "                value=dataset_embeddings\n",
    "            )\n",
    "            x_t = conditioned_embedding.squeeze(1) \n",
    "            \n",
    "            predicted_noise = tnet(x_t) if tnet is not None else self.forward(x_t) \n",
    "\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            \n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            \n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in train_loader:\n",
    "            formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predicted_emb = model(noisy_formula_emb)\n",
    "\n",
    "            loss = denoising_loss(predicted_emb, formula_emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in val_loader:\n",
    "                formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "                predicted_emb = model.reverse_diffusion(noisy_formula_emb, dataset_emb, schedule)\n",
    "                loss = denoising_loss(predicted_emb, formula_emb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                num_samples += formula_emb.size(0)\n",
    "\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "\n",
    "    if not early_stopping:\n",
    "        save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\") \n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "train_size = int(0.7*len(dataset))\n",
    "val_size = int(0.15*len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "num_heads = 4 \n",
    "embedding_dim = 128 \n",
    "hidden_dim = embedding_dim\n",
    "\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab,\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "    plt.figure();\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "    plt.title(f'{model_name} Training and Validation Loss');\n",
    "    plt.xlabel('Epochs');\n",
    "    plt.ylabel('Loss');\n",
    "    plt.legend();\n",
    "    plt.grid();\n",
    "    plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Diffusion Model'\n",
    "\n",
    "plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "    batch_size, embedding_dim, seq_length = embeddings.shape\n",
    "    vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])\n",
    "\n",
    "    embeddings_flattened = embeddings.view(batch_size*seq_length, embedding_dim)\n",
    "    \n",
    "    distances = torch.cdist(embeddings_flattened, vocab_embeddings)  # Shape: [batch_size * seq_length, num_symbols]\n",
    "\n",
    "    distances = distances.view(batch_size, seq_length, -1)\n",
    "    \n",
    "    # Find the index of the closest token for each position in the sequence\n",
    "    closest_token_indices = torch.argmin(distances, dim=-1)  # Shape: [batch_size, seq_length]\n",
    "    \n",
    "    # Convert indices to tokens\n",
    "    decoded_tokens = []\n",
    "    for batch_idx in range(batch_size):\n",
    "        tokens = [list(vocab.keys())[idx.item()] for idx in closest_token_indices[batch_idx]]\n",
    "        decoded_tokens.append(tokens)\n",
    "\n",
    "    return decoded_tokens\n",
    "\n",
    "def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0.0\n",
    "    decoded_formulas = []\n",
    "    actual_formulas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton_list in test_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            # Get the predicted denoised embeddings\n",
    "            t = random.randint(0, model.num_timesteps - 1)  # Random timestep for diffusion\n",
    "            pred_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "\n",
    "            # Calculate the loss (MSE between predicted and target embeddings)\n",
    "            loss = denoising_loss(pred_embeddings, noisy_token_embeddings)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Now, we need to decode the denoised embeddings back to tokens\n",
    "            decoded_tokens_list = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "\n",
    "            # Convert the decoded tokens to a formula string\n",
    "            predicted_formula = [\"\".join(decoded_tokens).replace('<PAD>', '').replace('+', ' + ') for decoded_tokens in decoded_tokens_list]\n",
    "            decoded_formulas.append(predicted_formula)\n",
    "\n",
    "            # Assuming target embeddings have a corresponding ground truth formula (you can adjust this part)\n",
    "            actual_formula = list(skeleton_list)\n",
    "            actual_formulas.append(actual_formula)\n",
    "\n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = total_test_loss/len(test_loader)\n",
    "    return avg_test_loss, decoded_formulas, actual_formulas\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "# Example: Evaluate the model on the test set\n",
    "model, device = load_model(model, \"Data/best_diffusion_model_method2.pt\")\n",
    "test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "# Print out the average test loss\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Print out the first few decoded formulas and their corresponding actual formulas\n",
    "for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "    print(f\"Predicted Formula: {predicted}\")\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_formulas = actual_formulas[0]\n",
    "decoded_formulas = decoded_formulas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def tokenize_skeleton(skeleton_str):\n",
    "    skeleton_str = skeleton_str.replace(\"**\", \"^\")\n",
    "    pattern = r'[a-zA-Z_][a-zA-Z0-9_]*|[+\\-*/^(),.]|C|sin|cos|log|exp|sqrt'\n",
    "    tokens = re.findall(pattern, skeleton_str)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(actual_formulas,decoded_formulas):\n",
    "    total_bleu = 0\n",
    "    smoothing = SmoothingFunction().method1\n",
    "\n",
    "    for actual_formula, reconstructed_formula in zip(actual_formulas,decoded_formulas):\n",
    "        reference = [tokenize_skeleton(actual_formula)]\n",
    "        candidate = tokenize_skeleton(reconstructed_formula)\n",
    "\n",
    "        bleu_score = sentence_bleu(reference, candidate, smoothing_function=smoothing)\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "    average_bleu = total_bleu / len(actual_formulas) if actual_formulas else 0\n",
    "    return average_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_bleu = calculate_bleu(actual_formulas,decoded_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022679879435846356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_token_accuracy(actual_formulas,decoded_formulas):\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    for actual_formula, reconstructed_formula in zip(actual_formulas,decoded_formulas):\n",
    "        actual_tokens = tokenize_skeleton(actual_formula)\n",
    "        reconstructed_tokens = tokenize_skeleton(reconstructed_formula)\n",
    "\n",
    "        total_tokens += len(actual_tokens)\n",
    "        correct_tokens += sum(1 for a, r in zip(actual_tokens, reconstructed_tokens) if a == r)\n",
    "\n",
    "    token_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    return token_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_accuracy = calculate_token_accuracy(actual_formulas,decoded_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029940119760479042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def calculate_edit_distance(actual_formulas,decoded_formulas):\n",
    "    total_distance = 0\n",
    "\n",
    "    for actual_formula, reconstructed_formula in zip(actual_formulas,decoded_formulas):\n",
    "        actual_tokens = tokenize_skeleton(actual_formula)\n",
    "        reconstructed_tokens = tokenize_skeleton(reconstructed_formula)\n",
    "        total_distance += edit_distance(actual_tokens, reconstructed_tokens)\n",
    "\n",
    "    average_distance = total_distance / len(actual_tokens) if actual_tokens else 0\n",
    "    return average_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_distance = calculate_edit_distance(actual_formulas,decoded_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.416666666666666"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edit_distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
